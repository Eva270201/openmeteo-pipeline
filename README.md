# Pipeline Big Data - Traitement Temps RÃ©el de DonnÃ©es MÃ©tÃ©orologiques

## ğŸ“‹ Description du Projet

Ce projet implÃ©mente un pipeline de donnÃ©es distribuÃ© pour le traitement temps rÃ©el de donnÃ©es mÃ©tÃ©orologiques. Le systÃ¨me collecte les donnÃ©es depuis l'API Open-Meteo, les traite via Apache Spark Streaming et les visualise dans Grafana.

### Objectifs
- DÃ©monstration d'un cluster Big Data distribuÃ©
- Traitement temps rÃ©el avec Kafka + Spark Streaming  
- Visualisation de mÃ©triques avec InfluxDB + Grafana
- Gestion de la charge et optimisation des ressources

### DÃ©fis RencontrÃ©s et Solutions
- **ProblÃ¨me initial** : Surcharge du Master (crashs frÃ©quents)
- **Solution appliquÃ©e** : 
  - RÃ©duction de 5 Ã  3 villes 
  - Intervalle de collecte de 10s â†’ 60s
  - Producer dÃ©placÃ© sur Worker1

## ğŸ—ï¸ Architecture DistribuÃ©e

### Configuration du Cluster (4 VMs Azure)
| Node | IP | CPU/RAM | Services |
|------|----|---------| ---------|
| Master | 10.0.0.110 | 4 vCPU / 8GB | NameNode, ResourceManager, InfluxDB, Grafana |
| Worker1 | 10.0.0.111 | 2 vCPU / 4GB | DataNode, Kafka Broker 1, ZooKeeper, Producer |
| Worker2 | 10.0.0.102 | 2 vCPU / 4GB | DataNode, Kafka Broker 2 |
| Worker3 | 10.0.0.103 | 2 vCPU / 4GB | DataNode, Kafka Broker 3 |

### Flux de DonnÃ©es
```
API Open-Meteo â†’ Producer Python â†’ Kafka (3 brokers) â†’ Spark Streaming â†’ InfluxDB â†’ Grafana
```

### Source de DonnÃ©es : API Open-Meteo
- **URL** : https://api.open-meteo.com/v1/forecast
- **Villes** : Paris, Nice, Strasbourg
- **MÃ©triques** : TempÃ©rature, vitesse du vent, humiditÃ©, pression
- **FrÃ©quence** : 60 secondes (optimisÃ© pour Ã©viter surcharge)

## ğŸš€ Guide de DÃ©marrage Complet

### PrÃ©requis
- 4 VMs Ubuntu configurÃ©es en rÃ©seau
- Java 11+ installÃ© sur tous les nodes
- Python 3.8+ avec pip et venv

### 1. Services Hadoop (sur Master)
```bash
# DÃ©marrer HDFS
start-dfs.sh

# VÃ©rifier HDFS
hdfs dfsadmin -report

# DÃ©marrer YARN
start-yarn.sh

# VÃ©rifier YARN
yarn node -list
```

### 2. SystÃ¨me Kafka DistribuÃ©

#### A. ZooKeeper (sur Worker1 UNIQUEMENT)
```bash
ssh adm-mcsc@10.0.0.111
cd /opt/kafka
./bin/zookeeper-server-start.sh -daemon config/zookeeper.properties

# VÃ©rifier ZooKeeper
jps | grep QuorumPeerMain
```

#### B. Brokers Kafka (sur TOUS les Workers)
```bash
# Sur Worker1
./bin/kafka-server-start.sh -daemon config/server.properties

# Sur Worker2
ssh adm-mcsc@10.0.0.102
cd /opt/kafka
./bin/kafka-server-start.sh -daemon config/server.properties

# Sur Worker3  
ssh adm-mcsc@10.0.0.103
cd /opt/kafka
./bin/kafka-server-start.sh -daemon config/server.properties
```

#### C. CrÃ©er le Topic
```bash
# Depuis n'importe quel node
/opt/kafka/bin/kafka-topics.sh --create \
  --topic open-meteo-weather \
  --bootstrap-server 10.0.0.111:9092,10.0.0.102:9092,10.0.0.103:9092 \
  --partitions 3 \
  --replication-factor 3

# VÃ©rifier la crÃ©ation
/opt/kafka/bin/kafka-topics.sh --describe \
  --topic open-meteo-weather \
  --bootstrap-server 10.0.0.111:9092,10.0.0.102:9092,10.0.0.103:9092
```

### 3. Base de DonnÃ©es InfluxDB (sur Master)
```bash
cd ~/influxdb2_linux_amd64
./influxd &

# Dans un autre terminal, configurer
influx setup \
  --username admin \
  --password adminpassword \
  --org admin \
  --bucket open_meteo_metrics \
  --force
```

### 4. Grafana (sur Master)
```bash
# Nouveau terminal
~/grafana-10.2.0/bin/grafana-server \
  --homepath ~/grafana-10.2.0 \
  --config ~/grafana-10.2.0/conf/defaults.ini &
```

## ğŸ”„ ExÃ©cution du Pipeline

### Ã‰tape 1 : Lancer le Producer de DonnÃ©es (sur Worker1)
```bash
# Se connecter au Worker1
ssh adm-mcsc@10.0.0.111
cd ~/streaming_project/spark_jobs

# CrÃ©er et activer l'environnement virtuel Python
python3 -m venv venv
source venv/bin/activate

# Installer les dÃ©pendances
pip install kafka-python requests

# Lancer le producer en arriÃ¨re-plan
python3 open_meteo_producer.py

# Pour lancer en arriÃ¨re-plan (optionnel)
nohup python3 open_meteo_producer.py > producer.log 2>&1 &

# VÃ©rifier les logs
tail -f producer.log
```

### Ã‰tape 2 : Lancer Spark Streaming (sur Master)
```bash
# Sur Master
cd ~/streaming_project/spark_jobs

# Configurer les variables d'environnement
export INFLUX_ORG="admin"
export INFLUX_BUCKET="open_meteo_metrics"
export INFLUX_TOKEN="votre-token-ici"

# Lancer le job Spark
spark-submit \
  --master yarn \
  --deploy-mode client \
  --executor-memory 1G \
  --executor-cores 1 \
  --num-executors 2 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 \
  spark_openmeteo_to_influx.py
```

### Ã‰tape 3 : AccÃ©der aux Interfaces
```bash
# Depuis votre machine locale - Tunnels SSH
ssh -L 8088:localhost:8088 -L 8086:localhost:8086 -L 3000:localhost:3000 adm-mcsc@master

# Puis ouvrir :
# - YARN UI : http://localhost:8088
# - InfluxDB : http://localhost:8086  
# - Grafana : http://localhost:3000
```

## ğŸ“Š Configuration Grafana

1. **Ajouter InfluxDB comme source** :
   - URL : `http://localhost:8086`
   - Organisation : `admin`
   - Token : votre token InfluxDB
   - Bucket : `open_meteo_metrics`

2. **RequÃªte exemple pour dashboard** :
```flux
from(bucket: "open_meteo_metrics")
  |> range(start: -1h)
  |> filter(fn: (r) => r["_measurement"] == "weather")
  |> filter(fn: (r) => r["_field"] == "temperature")
  |> aggregateWindow(every: 1m, fn: mean)
```

## ğŸ› ï¸ Technologies et Versions

- **Hadoop** : 3.3.6 (HDFS + YARN)
- **Apache Spark** : 3.5.1 (Structured Streaming)
- **Apache Kafka** : 3.7.2 (3 brokers + ZooKeeper)
- **InfluxDB** : 2.7.1 (Time Series Database)
- **Grafana** : 10.2.0 (Visualisation)
- **Python** : 3.8+ (Producer + librairies : kafka-python, requests)

## ğŸ” Monitoring et DÃ©pannage

### VÃ©rifier les Services
```bash
# Hadoop
jps  # Voir les processus Java
hdfs dfsadmin -report | head -10

# Kafka  
/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server 10.0.0.111:9092

# VÃ©rifier les messages Kafka
/opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server 10.0.0.111:9092 \
  --topic open-meteo-weather \
  --from-beginning \
  --max-messages 5
```

### Logs Importants
- Producer : `~/streaming_project/spark_jobs/producer.log`
- Spark : Interface YARN UI
- Kafka : `/opt/kafka/logs/`
- InfluxDB : Logs dans le terminal
- Grafana : Logs dans le terminal

## ğŸ¥ DÃ©monstration VidÃ©o
[Lien YouTube de la dÃ©monstration complÃ¨te](Ã -ajouter)

## ğŸ“„ License
MIT License - Voir fichier LICENSE
